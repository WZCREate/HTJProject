'''
æœ¬ç¨‹åºè¯»å– "MainCSV" æ–‡ä»¶ä¸­çš„è‚¡ç¥¨ä»£ç å¹¶è¯·æ±‚æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®å†™å…¥æ•°æ®åº“ (stock_zh_a_hist)
æ•°æ®è¡¨åä¸º é…ç½®æ–‡ä»¶ä¸­çš„ "buffer_table"
ç”¨äºæ‰¹é‡è¯·æ±‚é•¿æ—¶é—´èŒƒå›´, 
!!!!æ—¥å¸¸æ›´æ–°å‹¿ç”¨
æœ¬ç¨‹åºä¸ºå¤šçº¿ç¨‹ç‰ˆæœ¬, ä½¿ç”¨æ—¶æ–­å¼€ VPN
é™åˆ¶ï¼šæ¯å°æ—¶æœ€å¤šè¯·æ±‚300æ”¯è‚¡ç¥¨ï¼Œæœ€å¤§çº¿ç¨‹æ•°8
'''

import akshare as ak
import pandas as pd
import sys
import logging
import os
from datetime import datetime, timedelta
import time
from requests.exceptions import SSLError
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# ç¡®ä¿å¯¼å…¥å½“å‰é¡¹ç›®çš„CommonFuncæ¨¡å—
current_file_dir = os.path.dirname(os.path.abspath(__file__))  # QA/SubFunc/
qa_func_dir = os.path.dirname(current_file_dir)               # QA/
project_root = os.path.dirname(qa_func_dir)                  # StockFilter/
if project_root not in sys.path:
    sys.path.insert(0, project_root)  # å°†å½“å‰é¡¹ç›®è·¯å¾„æ’å…¥åˆ°æœ€å‰é¢

from CommonFunc.DBconnection import find_config_path, load_config, set_log, db_con_pymysql
import random
import requests

# å…¨å±€è¯·æ±‚é™åˆ¶å™¨
class RequestLimiter:
    def __init__(self, max_requests_per_hour=300):
        self.max_requests_per_hour = max_requests_per_hour
        self.request_times = []
        self.lock = threading.Lock()
        
    def can_make_request(self):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å‘èµ·æ–°è¯·æ±‚"""
        with self.lock:
            current_time = time.time()
            # æ¸…ç†ä¸€å°æ—¶å‰çš„è¯·æ±‚è®°å½•
            self.request_times = [t for t in self.request_times if current_time - t < 3600]
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            return len(self.request_times) < self.max_requests_per_hour
    
    def record_request(self):
        """è®°å½•ä¸€æ¬¡è¯·æ±‚"""
        with self.lock:
            self.request_times.append(time.time())
    
    def get_wait_time(self):
        """è·å–éœ€è¦ç­‰å¾…çš„æ—¶é—´ï¼ˆç§’ï¼‰"""
        with self.lock:
            if not self.request_times:
                return 0
            
            current_time = time.time()
            # æ¸…ç†ä¸€å°æ—¶å‰çš„è¯·æ±‚è®°å½•
            self.request_times = [t for t in self.request_times if current_time - t < 3600]
            
            if len(self.request_times) < self.max_requests_per_hour:
                return 0
            
            # è®¡ç®—éœ€è¦ç­‰å¾…åˆ°æœ€æ—©è¯·æ±‚è¿‡æœŸçš„æ—¶é—´
            oldest_request = min(self.request_times)
            wait_time = 3600 - (current_time - oldest_request) + 1  # å¤šç­‰1ç§’ç¡®ä¿å®‰å…¨
            return max(0, wait_time)
    
    def get_current_count(self):
        """è·å–å½“å‰å°æ—¶å†…çš„è¯·æ±‚æ•°é‡"""
        with self.lock:
            current_time = time.time()
            self.request_times = [t for t in self.request_times if current_time - t < 3600]
            return len(self.request_times)

# å…¨å±€è¯·æ±‚é™åˆ¶å™¨å®ä¾‹
request_limiter = RequestLimiter(max_requests_per_hour=300)

def check_and_clear_table(connection, table_name, logger):
    """æ¸…ç©ºæŒ‡å®šè¡¨"""
    try:
        with connection.cursor() as cursor:
            cursor.execute(f"TRUNCATE TABLE {table_name}")
            logger.info_print(f"æˆåŠŸæ¸…ç©ºè¡¨ {table_name}")
        return True
        
    except Exception as e:
        logger.error_print(f"æ¸…ç©ºè¡¨ {table_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

def process_single_stock(stock, logger, config, start_date, end_date):
    """å¤„ç†å•ä¸ªè‚¡ç¥¨çš„æ•°æ®è·å–å’Œä¿å­˜"""
    try:
        # æ£€æŸ¥è¯·æ±‚é™åˆ¶
        if not request_limiter.can_make_request():
            wait_time = request_limiter.get_wait_time()
            logger.warning_print(f"è‚¡ç¥¨ {stock} è¾¾åˆ°æ¯å°æ—¶è¯·æ±‚é™åˆ¶ï¼Œéœ€ç­‰å¾… {wait_time:.0f} ç§’")
            time.sleep(wait_time)
        
        # è®°å½•è¯·æ±‚
        request_limiter.record_request()
        
        # å»ºç«‹æ•°æ®åº“è¿æ¥ï¼ˆæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹çš„è¿æ¥ï¼‰
        connection = db_con_pymysql(config)
        
        try:
            # è·å–è‚¡ç¥¨æ•°æ®ï¼Œæ·»åŠ é‡è¯•æœºåˆ¶
            retries = 3
            timeout = 30  # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º30ç§’
            
            while retries > 0:
                try:
                    # æ·»åŠ éšæœºå»¶æ—¶ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    time.sleep(random.uniform(1.0, 3.0))  # å¢åŠ å»¶æ—¶èŒƒå›´
                    
                    stock_data = ak.stock_zh_a_hist(
                        symbol=stock,
                        period="daily",
                        start_date=start_date,
                        end_date=end_date,
                        adjust="qfq",
                        timeout=timeout
                    )
                    
                    # è¯·æ±‚æˆåŠŸï¼Œæ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
                    if stock_data is None or stock_data.empty:
                        logger.warning_print(f"è‚¡ç¥¨ {stock} åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ— æ•°æ®")
                        return "no_data"  # ç›´æ¥è¿”å›æ— æ•°æ®çŠ¶æ€ï¼Œä¸è¿›è¡Œé‡è¯•
                    
                    # æ•°æ®è·å–æˆåŠŸä¸”ä¸ä¸ºç©ºï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    break
                        
                except (SSLError, requests.exceptions.Timeout, 
                        requests.exceptions.ConnectionError) as e:
                    retries -= 1
                    if retries > 0:
                        wait_time = (3 - retries) * 5  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š5, 10ç§’
                        logger.warning_print(f"è‚¡ç¥¨ {stock} è¿æ¥é”™è¯¯: {str(e)[:100]}ï¼Œå°†åœ¨{wait_time}ç§’åè¿›è¡Œç¬¬ {3-retries} æ¬¡é‡è¯•")
                        time.sleep(wait_time)
                    else:
                        logger.error_print(f"è‚¡ç¥¨ {stock} åœ¨é‡è¯•3æ¬¡åä»ç„¶å¤±è´¥: {str(e)[:100]}")
                        return "api_fail"
                    continue
            
            # å‡†å¤‡æ•°æ®
            data_to_insert = [
                (
                    row["æ—¥æœŸ"], stock, row["å¼€ç›˜"], row["æ”¶ç›˜"], row["æœ€é«˜"],
                    row["æœ€ä½"], row["æˆäº¤é‡"], row["æˆäº¤é¢"], row["æŒ¯å¹…"], row["æ¶¨è·Œå¹…"],
                    row["æ¶¨è·Œé¢"], row["æ¢æ‰‹ç‡"]
                )
                for _, row in stock_data.iterrows()
            ]
            
            try:
                with connection.cursor() as cursor:
                    # æ’å…¥æ•°æ®
                    insert_query = f"""
                    INSERT INTO {config["DB_tables"]["buffer_table"]} (
                        date, id, open_price, close_price, high, low, volume, 
                        turnover, amplitude, chg_percen, chg_amount, turnover_rate,
                        Insrt_time, Latest
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), 0)
                    """
                    cursor.executemany(insert_query, data_to_insert)
                    connection.commit()
                    logger.info_print(f"âœ“ è‚¡ç¥¨ {stock} æˆåŠŸè·å–å¹¶å…¥åº“ {len(data_to_insert)} æ¡è®°å½•")
                    return "success"
                    
            except Exception as e:
                connection.rollback()
                logger.error_print(f"è‚¡ç¥¨ {stock} æ•°æ®åº“å†™å…¥å¤±è´¥: {str(e)}")
                return "db_fail"
                
        except Exception as e:
            logger.error_print(f"è‚¡ç¥¨ {stock} çš„æ•°æ®è·å–å¤±è´¥: {str(e)}")
            return "api_fail"
            
        finally:
            connection.close()
            
    except Exception as e:
        logger.error_print(f"è‚¡ç¥¨ {stock} å¤„ç†è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
        return "error"

def main():
    """ä¸»å‡½æ•°"""
    config_path, _, root_dir = find_config_path()
    config = load_config(config_path)
    logger = set_log(config, "SubQA002_MulTh.log", "QA")  # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger.info_print("ğŸ“‹ é™åˆ¶æ¡ä»¶ï¼šæ¯å°æ—¶æœ€å¤š300æ”¯è‚¡ç¥¨ï¼Œæœ€å¤§8ä¸ªå¹¶å‘çº¿ç¨‹")

    try:
        connection = db_con_pymysql(config)
        if check_and_clear_table(connection, config["DB_tables"]["buffer_table"], logger):
            # è¯»å–è‚¡ç¥¨åˆ—è¡¨
            csv_path = os.path.join(root_dir, "QA", config["CSVs"]["MainCSV"])
            stock_list_df = pd.read_csv(csv_path, dtype={1: str})
            stock_codes = stock_list_df.iloc[:, 1].tolist()
            
            start_date = config["ProgormInput"]["massive_insrt_start_date"]
            end_date = config["ProgormInput"]["massive_insrt_end_date"]
            
            total_stocks = len(stock_codes)
            logger.info_print(f"æˆåŠŸè¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {total_stocks} åªè‚¡ç¥¨")
            logger.info_print(f"æ•°æ®è·å–æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
            
            # è®¡ç®—é¢„ä¼°å®Œæˆæ—¶é—´
            estimated_hours = (total_stocks / 300) + 1  # åŠ 1å°æ—¶ç¼“å†²
            logger.info_print(f"é¢„ä¼°å®Œæˆæ—¶é—´: {estimated_hours:.1f} å°æ—¶")
            
            # åˆå§‹åŒ–è®¡æ•°å™¨
            api_success = 0
            db_success = 0
            no_data_stocks = []
            failed_stocks = []
            completed = 0
            start_time = time.time()
            
            # ä½¿ç”¨è¾ƒå°çš„çº¿ç¨‹æ± å¤„ç†æ‰€æœ‰æ•°æ®
            max_workers = 8  # çº¿ç¨‹æ•°
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                futures = {
                    executor.submit(
                        process_single_stock, 
                        stock, 
                        logger,  # ä¼ é€’loggerç»™process_single_stock
                        config, 
                        start_date, 
                        end_date
                    ): stock for stock in stock_codes
                }
                
                # è·å–ä»»åŠ¡ç»“æœ
                for future in as_completed(futures):
                    stock = futures[future]
                    completed += 1
                    current_hour_requests = request_limiter.get_current_count()
                    
                    try:
                        result = future.result()
                        if result == "success":
                            api_success += 1
                            db_success += 1
                        elif result == "no_data":
                            no_data_stocks.append(stock)
                            logger.warning_print(f"è‚¡ç¥¨ {stock} åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ— æ•°æ®")
                        elif result == "api_fail":
                            failed_stocks.append(stock)
                            logger.error_print(f"è‚¡ç¥¨ {stock} APIè¯·æ±‚å¤±è´¥")
                        elif result == "db_fail":
                            api_success += 1
                            failed_stocks.append(stock)
                            logger.error_print(f"è‚¡ç¥¨ {stock} æ•°æ®åº“å†™å…¥å¤±è´¥")
                        else:
                            failed_stocks.append(stock)
                            logger.error_print(f"è‚¡ç¥¨ {stock} å¤„ç†å¤±è´¥ï¼ŒæœªçŸ¥åŸå› ")
                            
                    except Exception as e:
                        logger.error_print(f"è‚¡ç¥¨ {stock} æ‰§è¡Œå‡ºç°å¼‚å¸¸: {str(e)}")
                        failed_stocks.append(stock)
                    
                    finally:
                        # è®¡ç®—é€Ÿåº¦å’Œå‰©ä½™æ—¶é—´
                        elapsed_time = time.time() - start_time
                        if elapsed_time > 0:
                            speed = completed / elapsed_time * 3600  # æ¯å°æ—¶å¤„ç†çš„è‚¡ç¥¨æ•°
                            remaining = total_stocks - completed
                            eta = remaining / max(speed, 1) if speed > 0 else 0
                        else:
                            speed = 0
                            eta = 0
                        
                        # æ— è®ºæˆåŠŸå¤±è´¥éƒ½æ›´æ–°è¿›åº¦
                        print(f"\rè¿›åº¦: {completed}/{total_stocks} | "
                              f"æˆåŠŸç‡: {api_success/completed:.1%} | "
                              f"æœ¬å°æ—¶è¯·æ±‚: {current_hour_requests}/300 | "
                              f"é€Ÿåº¦: {speed:.0f}è‚¡/æ—¶ | "
                              f"é¢„è®¡å‰©ä½™: {eta:.1f}å°æ—¶", 
                              end="", flush=True)
                        
                        # æ¯å¤„ç†100åªè‚¡ç¥¨è¾“å‡ºä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
                        if completed % 100 == 0:
                            print()  # æ¢è¡Œ
                            logger.info_print(f"ğŸ“Š å·²å¤„ç† {completed}/{total_stocks} åªè‚¡ç¥¨")
                            logger.info_print(f"ğŸ“ˆ å½“å‰æˆåŠŸç‡: {api_success/completed:.1%}")
                            logger.info_print(f"ğŸ• æœ¬å°æ—¶å·²è¯·æ±‚: {current_hour_requests}/300")
                            logger.info_print(f"âš¡ å¤„ç†é€Ÿåº¦: {speed:.0f} è‚¡ç¥¨/å°æ—¶")
            
            print()  # æ¢è¡Œ
            
            # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - start_time
            final_speed = completed / total_time * 3600 if total_time > 0 else 0
            
            # æ‰“å°æœ€ç»ˆç»“æœ
            logger.info_print("="*60)
            logger.info_print("ğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆ!")
            logger.info_print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            logger.info_print(f"  - æ€»å¤„ç†è‚¡ç¥¨: {completed}")
            logger.info_print(f"  - æˆåŠŸè·å–: {api_success} ({api_success/completed:.1%})")
            logger.info_print(f"  - æ•°æ®åº“æˆåŠŸ: {db_success} ({db_success/completed:.1%})")
            logger.info_print(f"  - æ— æ•°æ®è‚¡ç¥¨: {len(no_data_stocks)}")
            logger.info_print(f"  - å¤±è´¥è‚¡ç¥¨: {len(failed_stocks)}")
            logger.info_print(f"â±ï¸  æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
            logger.info_print(f"âš¡ å¹³å‡é€Ÿåº¦: {final_speed:.0f} è‚¡ç¥¨/å°æ—¶")
            logger.info_print("="*60)
            
            if no_data_stocks:
                logger.warning_print(f"âš ï¸  æ— æ•°æ®è‚¡ç¥¨ ({len(no_data_stocks)} åª): {', '.join(no_data_stocks[:10])}{'...' if len(no_data_stocks) > 10 else ''}")
            if failed_stocks:
                logger.warning_print(f"âŒ å¤±è´¥è‚¡ç¥¨ ({len(failed_stocks)} åª): {', '.join(failed_stocks[:10])}{'...' if len(failed_stocks) > 10 else ''}")
            
            return True

    except Exception as e:
        logger.error_print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        result = main()
        if result:
            print("âœ… ç¨‹åºæ­£å¸¸ç»“æŸ")
            sys.exit(0)
        else:
            print("âŒ ç¨‹åºæœªæ­£å¸¸å®Œæˆ")
            sys.exit(1)
    except Exception as e:
        print(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")
        sys.exit(1)